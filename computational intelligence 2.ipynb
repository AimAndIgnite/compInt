{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regression+classification UAS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDAoHGALCmUR"
      },
      "source": [
        "#1. Import Relevant Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6fr6cwj_NF-"
      },
      "source": [
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1y2w3p7CrSS"
      },
      "source": [
        "#2. Upload Files to Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7ngeT3wCvD3"
      },
      "source": [
        "This section of code uploads the communities.csv dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "n79FW7z7-2x2",
        "outputId": "323f0c82-c5a4-4d7a-b8f0-5219414c04b6"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-06db5655-dee7-4800-9969-07376378acc0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-06db5655-dee7-4800-9969-07376378acc0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving communities.csv to communities.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvcbvKVcCuZF"
      },
      "source": [
        "This section of code uploads the attributes of the communities.csv dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "0ACYcxuzBcBt",
        "outputId": "d93e85c3-6bb9-48ca-fbdf-739fd79e261f"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bb825711-6e3a-4458-98e1-33d5c03ede49\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bb825711-6e3a-4458-98e1-33d5c03ede49\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving attributes.csv to attributes.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y28bf2EHBmyj"
      },
      "source": [
        "attrib = read_csv('attributes.csv', delim_whitespace = True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am51kEINC8jV"
      },
      "source": [
        "Here, we read the communities.csv dataset and combine it with the attributes from the attributes.csv."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQp-HIblBpGh"
      },
      "source": [
        "data = read_csv('communities.csv', names = attrib['attributes'], sep = ';')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J383DT3DDDDp"
      },
      "source": [
        "The final combination looks as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "6yn1_boi_Y75",
        "outputId": "61686875-1ea7-4f01-ad61-88c7be414ca9"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>state</th>\n",
              "      <th>county</th>\n",
              "      <th>community</th>\n",
              "      <th>communityname</th>\n",
              "      <th>fold</th>\n",
              "      <th>population</th>\n",
              "      <th>householdsize</th>\n",
              "      <th>racepctblack</th>\n",
              "      <th>racePctWhite</th>\n",
              "      <th>racePctAsian</th>\n",
              "      <th>racePctHisp</th>\n",
              "      <th>agePct12t21</th>\n",
              "      <th>agePct12t29</th>\n",
              "      <th>agePct16t24</th>\n",
              "      <th>agePct65up</th>\n",
              "      <th>numbUrban</th>\n",
              "      <th>pctUrban</th>\n",
              "      <th>medIncome</th>\n",
              "      <th>pctWWage</th>\n",
              "      <th>pctWFarmSelf</th>\n",
              "      <th>pctWInvInc</th>\n",
              "      <th>pctWSocSec</th>\n",
              "      <th>pctWPubAsst</th>\n",
              "      <th>pctWRetire</th>\n",
              "      <th>medFamInc</th>\n",
              "      <th>perCapInc</th>\n",
              "      <th>whitePerCap</th>\n",
              "      <th>blackPerCap</th>\n",
              "      <th>indianPerCap</th>\n",
              "      <th>AsianPerCap</th>\n",
              "      <th>OtherPerCap</th>\n",
              "      <th>HispPerCap</th>\n",
              "      <th>NumUnderPov</th>\n",
              "      <th>PctPopUnderPov</th>\n",
              "      <th>PctLess9thGrade</th>\n",
              "      <th>PctNotHSGrad</th>\n",
              "      <th>PctBSorMore</th>\n",
              "      <th>PctUnemployed</th>\n",
              "      <th>PctEmploy</th>\n",
              "      <th>PctEmplManu</th>\n",
              "      <th>...</th>\n",
              "      <th>RentMedian</th>\n",
              "      <th>RentHighQ</th>\n",
              "      <th>MedRent</th>\n",
              "      <th>MedRentPctHousInc</th>\n",
              "      <th>MedOwnCostPctInc</th>\n",
              "      <th>MedOwnCostPctIncNoMtg</th>\n",
              "      <th>NumInShelters</th>\n",
              "      <th>NumStreet</th>\n",
              "      <th>PctForeignBorn</th>\n",
              "      <th>PctBornSameState</th>\n",
              "      <th>PctSameHouse85</th>\n",
              "      <th>PctSameCity85</th>\n",
              "      <th>PctSameState85</th>\n",
              "      <th>LemasSwornFT</th>\n",
              "      <th>LemasSwFTPerPop</th>\n",
              "      <th>LemasSwFTFieldOps</th>\n",
              "      <th>LemasSwFTFieldPerPop</th>\n",
              "      <th>LemasTotalReq</th>\n",
              "      <th>LemasTotReqPerPop</th>\n",
              "      <th>PolicReqPerOffic</th>\n",
              "      <th>PolicPerPop</th>\n",
              "      <th>RacialMatchCommPol</th>\n",
              "      <th>PctPolicWhite</th>\n",
              "      <th>PctPolicBlack</th>\n",
              "      <th>PctPolicHisp</th>\n",
              "      <th>PctPolicAsian</th>\n",
              "      <th>PctPolicMinor</th>\n",
              "      <th>OfficAssgnDrugUnits</th>\n",
              "      <th>NumKindsDrugsSeiz</th>\n",
              "      <th>PolicAveOTWorked</th>\n",
              "      <th>LandArea</th>\n",
              "      <th>PopDens</th>\n",
              "      <th>PctUsePubTrans</th>\n",
              "      <th>PolicCars</th>\n",
              "      <th>PolicOperBudg</th>\n",
              "      <th>LemasPctPolicOnPatr</th>\n",
              "      <th>LemasGangUnitDeploy</th>\n",
              "      <th>LemasPctOfficDrugUn</th>\n",
              "      <th>PolicBudgPerPop</th>\n",
              "      <th>ViolentCrimesPerPop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>Lakewoodcity</td>\n",
              "      <td>1</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.23</td>\n",
              "      <td>...</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>Tukwilacity</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.02</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.57</td>\n",
              "      <td>...</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.52</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.45</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.00</td>\n",
              "      <td>?</td>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>24</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>Aberdeentown</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.32</td>\n",
              "      <td>...</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.56</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.02</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.00</td>\n",
              "      <td>?</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>34</td>\n",
              "      <td>5</td>\n",
              "      <td>81440</td>\n",
              "      <td>Willingborotownship</td>\n",
              "      <td>1</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.77</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.36</td>\n",
              "      <td>...</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.65</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.28</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.00</td>\n",
              "      <td>?</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>42</td>\n",
              "      <td>95</td>\n",
              "      <td>6096</td>\n",
              "      <td>Bethlehemtownship</td>\n",
              "      <td>1</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.67</td>\n",
              "      <td>...</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.53</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.02</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.00</td>\n",
              "      <td>?</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 128 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   state county  ... PolicBudgPerPop ViolentCrimesPerPop\n",
              "0      8      ?  ...            0.14                0.20\n",
              "1     53      ?  ...               ?                0.67\n",
              "2     24      ?  ...               ?                0.43\n",
              "3     34      5  ...               ?                0.12\n",
              "4     42     95  ...               ?                0.03\n",
              "\n",
              "[5 rows x 128 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41dVVRvpDHJf"
      },
      "source": [
        "#3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Puxo3sgUO3F1",
        "outputId": "2807aef7-955c-4e35-a6de-584dfc79ff15"
      },
      "source": [
        "print(data.dtypes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "state                    int64\n",
            "county                  object\n",
            "community               object\n",
            "communityname           object\n",
            "fold                     int64\n",
            "                        ...   \n",
            "LemasPctPolicOnPatr     object\n",
            "LemasGangUnitDeploy     object\n",
            "LemasPctOfficDrugUn    float64\n",
            "PolicBudgPerPop         object\n",
            "ViolentCrimesPerPop    float64\n",
            "Length: 128, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DzVDs2hVDJ60"
      },
      "source": [
        "There are several attributes within the communities dataset that do not contain predictive values. \n",
        "\n",
        "These attributes include:\n",
        "* state\n",
        "* county\n",
        "* community\n",
        "* communityname\n",
        "* fold\n",
        "\n",
        "As such, we can drop them instead. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crGwfGA8CfXZ"
      },
      "source": [
        "data = data.drop(columns=['state','county', 'community','communityname', 'fold'], axis=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axlpglwqEEAY"
      },
      "source": [
        "The dataset after the columns above are dropped shall be as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "1gUwCJu3EBtP",
        "outputId": "c1769b75-fd08-4391-a96d-e5e19eda73df"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>population</th>\n",
              "      <th>householdsize</th>\n",
              "      <th>racepctblack</th>\n",
              "      <th>racePctWhite</th>\n",
              "      <th>racePctAsian</th>\n",
              "      <th>racePctHisp</th>\n",
              "      <th>agePct12t21</th>\n",
              "      <th>agePct12t29</th>\n",
              "      <th>agePct16t24</th>\n",
              "      <th>agePct65up</th>\n",
              "      <th>numbUrban</th>\n",
              "      <th>pctUrban</th>\n",
              "      <th>medIncome</th>\n",
              "      <th>pctWWage</th>\n",
              "      <th>pctWFarmSelf</th>\n",
              "      <th>pctWInvInc</th>\n",
              "      <th>pctWSocSec</th>\n",
              "      <th>pctWPubAsst</th>\n",
              "      <th>pctWRetire</th>\n",
              "      <th>medFamInc</th>\n",
              "      <th>perCapInc</th>\n",
              "      <th>whitePerCap</th>\n",
              "      <th>blackPerCap</th>\n",
              "      <th>indianPerCap</th>\n",
              "      <th>AsianPerCap</th>\n",
              "      <th>OtherPerCap</th>\n",
              "      <th>HispPerCap</th>\n",
              "      <th>NumUnderPov</th>\n",
              "      <th>PctPopUnderPov</th>\n",
              "      <th>PctLess9thGrade</th>\n",
              "      <th>PctNotHSGrad</th>\n",
              "      <th>PctBSorMore</th>\n",
              "      <th>PctUnemployed</th>\n",
              "      <th>PctEmploy</th>\n",
              "      <th>PctEmplManu</th>\n",
              "      <th>PctEmplProfServ</th>\n",
              "      <th>PctOccupManu</th>\n",
              "      <th>PctOccupMgmtProf</th>\n",
              "      <th>MalePctDivorce</th>\n",
              "      <th>MalePctNevMarr</th>\n",
              "      <th>...</th>\n",
              "      <th>RentMedian</th>\n",
              "      <th>RentHighQ</th>\n",
              "      <th>MedRent</th>\n",
              "      <th>MedRentPctHousInc</th>\n",
              "      <th>MedOwnCostPctInc</th>\n",
              "      <th>MedOwnCostPctIncNoMtg</th>\n",
              "      <th>NumInShelters</th>\n",
              "      <th>NumStreet</th>\n",
              "      <th>PctForeignBorn</th>\n",
              "      <th>PctBornSameState</th>\n",
              "      <th>PctSameHouse85</th>\n",
              "      <th>PctSameCity85</th>\n",
              "      <th>PctSameState85</th>\n",
              "      <th>LemasSwornFT</th>\n",
              "      <th>LemasSwFTPerPop</th>\n",
              "      <th>LemasSwFTFieldOps</th>\n",
              "      <th>LemasSwFTFieldPerPop</th>\n",
              "      <th>LemasTotalReq</th>\n",
              "      <th>LemasTotReqPerPop</th>\n",
              "      <th>PolicReqPerOffic</th>\n",
              "      <th>PolicPerPop</th>\n",
              "      <th>RacialMatchCommPol</th>\n",
              "      <th>PctPolicWhite</th>\n",
              "      <th>PctPolicBlack</th>\n",
              "      <th>PctPolicHisp</th>\n",
              "      <th>PctPolicAsian</th>\n",
              "      <th>PctPolicMinor</th>\n",
              "      <th>OfficAssgnDrugUnits</th>\n",
              "      <th>NumKindsDrugsSeiz</th>\n",
              "      <th>PolicAveOTWorked</th>\n",
              "      <th>LandArea</th>\n",
              "      <th>PopDens</th>\n",
              "      <th>PctUsePubTrans</th>\n",
              "      <th>PolicCars</th>\n",
              "      <th>PolicOperBudg</th>\n",
              "      <th>LemasPctPolicOnPatr</th>\n",
              "      <th>LemasGangUnitDeploy</th>\n",
              "      <th>LemasPctOfficDrugUn</th>\n",
              "      <th>PolicBudgPerPop</th>\n",
              "      <th>ViolentCrimesPerPop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.19</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.40</td>\n",
              "      <td>...</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.93</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.02</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.36</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.52</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.45</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.00</td>\n",
              "      <td>?</td>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.41</td>\n",
              "      <td>...</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.56</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.02</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.00</td>\n",
              "      <td>?</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.04</td>\n",
              "      <td>0.77</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.45</td>\n",
              "      <td>...</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.65</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.28</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.00</td>\n",
              "      <td>?</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.27</td>\n",
              "      <td>...</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.53</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.02</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>0.00</td>\n",
              "      <td>?</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 123 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   population  householdsize  ...  PolicBudgPerPop  ViolentCrimesPerPop\n",
              "0        0.19           0.33  ...             0.14                 0.20\n",
              "1        0.00           0.16  ...                ?                 0.67\n",
              "2        0.00           0.42  ...                ?                 0.43\n",
              "3        0.04           0.77  ...                ?                 0.12\n",
              "4        0.01           0.55  ...                ?                 0.03\n",
              "\n",
              "[5 rows x 123 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfiJmN_EFvAh"
      },
      "source": [
        "Since the dataset contains \"?\", it is read as a valid value when they are actually a missing value.\n",
        "\n",
        "Therefore, we change the value of \"?\" to a proper representation of a missing value with np.nan, where \"?\" will be replaced with \"NaN\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-Fm6hNfEK_X"
      },
      "source": [
        "data = data.replace('?', np.nan)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFUD_68FGRCV"
      },
      "source": [
        "We can now calculate the missing values for each attribute.\n",
        "\n",
        "From the code below, we can see that an attribute is supposed to have 1994 values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKr-YYgRFk2a",
        "outputId": "c03912ff-b08e-4010-800e-6be0a4fa607d"
      },
      "source": [
        "print(data.count())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "population             1994\n",
            "householdsize          1994\n",
            "racepctblack           1994\n",
            "racePctWhite           1994\n",
            "racePctAsian           1994\n",
            "                       ... \n",
            "LemasPctPolicOnPatr     319\n",
            "LemasGangUnitDeploy     319\n",
            "LemasPctOfficDrugUn    1994\n",
            "PolicBudgPerPop         319\n",
            "ViolentCrimesPerPop    1994\n",
            "Length: 123, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVX5oAxkH43M"
      },
      "source": [
        "There are several attributes that are missing lots of values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56Yk-CQOH9PA",
        "outputId": "59845e8b-0558-4a27-8f52-f48b640d36fb"
      },
      "source": [
        "attr_missing_values = data.columns[data.isnull().any()] \n",
        "print(attr_missing_values)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['OtherPerCap', 'LemasSwornFT', 'LemasSwFTPerPop', 'LemasSwFTFieldOps',\n",
            "       'LemasSwFTFieldPerPop', 'LemasTotalReq', 'LemasTotReqPerPop',\n",
            "       'PolicReqPerOffic', 'PolicPerPop', 'RacialMatchCommPol',\n",
            "       'PctPolicWhite', 'PctPolicBlack', 'PctPolicHisp', 'PctPolicAsian',\n",
            "       'PctPolicMinor', 'OfficAssgnDrugUnits', 'NumKindsDrugsSeiz',\n",
            "       'PolicAveOTWorked', 'PolicCars', 'PolicOperBudg', 'LemasPctPolicOnPatr',\n",
            "       'LemasGangUnitDeploy', 'PolicBudgPerPop'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI_TJ7RfInD5"
      },
      "source": [
        "We can find these attributes with missing values and store them in a variable called _attr_missing_values_. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "FehqrU-lIR1-",
        "outputId": "6f071ec0-bfdd-4b59-83c4-b4a265188880"
      },
      "source": [
        "data[attr_missing_values].describe()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>OtherPerCap</th>\n",
              "      <th>LemasSwornFT</th>\n",
              "      <th>LemasSwFTPerPop</th>\n",
              "      <th>LemasSwFTFieldOps</th>\n",
              "      <th>LemasSwFTFieldPerPop</th>\n",
              "      <th>LemasTotalReq</th>\n",
              "      <th>LemasTotReqPerPop</th>\n",
              "      <th>PolicReqPerOffic</th>\n",
              "      <th>PolicPerPop</th>\n",
              "      <th>RacialMatchCommPol</th>\n",
              "      <th>PctPolicWhite</th>\n",
              "      <th>PctPolicBlack</th>\n",
              "      <th>PctPolicHisp</th>\n",
              "      <th>PctPolicAsian</th>\n",
              "      <th>PctPolicMinor</th>\n",
              "      <th>OfficAssgnDrugUnits</th>\n",
              "      <th>NumKindsDrugsSeiz</th>\n",
              "      <th>PolicAveOTWorked</th>\n",
              "      <th>PolicCars</th>\n",
              "      <th>PolicOperBudg</th>\n",
              "      <th>LemasPctPolicOnPatr</th>\n",
              "      <th>LemasGangUnitDeploy</th>\n",
              "      <th>PolicBudgPerPop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1993</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "      <td>319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>97</td>\n",
              "      <td>38</td>\n",
              "      <td>52</td>\n",
              "      <td>34</td>\n",
              "      <td>55</td>\n",
              "      <td>44</td>\n",
              "      <td>59</td>\n",
              "      <td>75</td>\n",
              "      <td>52</td>\n",
              "      <td>76</td>\n",
              "      <td>74</td>\n",
              "      <td>73</td>\n",
              "      <td>54</td>\n",
              "      <td>50</td>\n",
              "      <td>72</td>\n",
              "      <td>30</td>\n",
              "      <td>15</td>\n",
              "      <td>77</td>\n",
              "      <td>63</td>\n",
              "      <td>38</td>\n",
              "      <td>72</td>\n",
              "      <td>3</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.98</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>129</td>\n",
              "      <td>80</td>\n",
              "      <td>19</td>\n",
              "      <td>81</td>\n",
              "      <td>17</td>\n",
              "      <td>55</td>\n",
              "      <td>23</td>\n",
              "      <td>15</td>\n",
              "      <td>19</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>23</td>\n",
              "      <td>72</td>\n",
              "      <td>189</td>\n",
              "      <td>14</td>\n",
              "      <td>48</td>\n",
              "      <td>54</td>\n",
              "      <td>12</td>\n",
              "      <td>27</td>\n",
              "      <td>69</td>\n",
              "      <td>13</td>\n",
              "      <td>126</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       OtherPerCap LemasSwornFT  ... LemasGangUnitDeploy PolicBudgPerPop\n",
              "count         1993          319  ...                 319             319\n",
              "unique          97           38  ...                   3              51\n",
              "top              0         0.02  ...                   0            0.12\n",
              "freq           129           80  ...                 126              22\n",
              "\n",
              "[4 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hckJpadjIdPy"
      },
      "source": [
        "We can see that the attribute OtherPerCap is only missing 1 value (1993 out of 1994), and the rest only contain 319 values out of 1994.\n",
        "\n",
        "Therefore, we can impute the missing value of OtherPerCap. We will then drop the remaining attributes from attr_missing_values as they contain too many missing values.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvI9Q914JHOT"
      },
      "source": [
        "data['OtherPerCap'].fillna(data['OtherPerCap'].median(skipna=True), inplace=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85YADe2eLDAj"
      },
      "source": [
        "data = data.dropna(axis=1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PqZm1ylGLBa7"
      },
      "source": [
        "\n",
        "We will impute the missing value with the median data of the value from the attribute 'OtherPerCap'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXsk9qaQPvMv"
      },
      "source": [
        "data['OtherPerCap'] = np.asarray(data['OtherPerCap']).astype(np.float64)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKvPExZ7JqI5"
      },
      "source": [
        "We can then check the amount of values of 'OtherPerCap', which should be 1994."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35WiUfj0JbzN",
        "outputId": "a3ec98b8-da5b-44ca-f4da-b85446abdd01"
      },
      "source": [
        "data['OtherPerCap'].describe()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1994.000000\n",
              "mean        0.284724\n",
              "std         0.190962\n",
              "min         0.000000\n",
              "25%         0.170000\n",
              "50%         0.250000\n",
              "75%         0.360000\n",
              "max         1.000000\n",
              "Name: OtherPerCap, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "HSR0FfbOLTrZ",
        "outputId": "cff133a1-e0c7-4ba0-ecd3-e4fda5676cbc"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>population</th>\n",
              "      <th>householdsize</th>\n",
              "      <th>racepctblack</th>\n",
              "      <th>racePctWhite</th>\n",
              "      <th>racePctAsian</th>\n",
              "      <th>racePctHisp</th>\n",
              "      <th>agePct12t21</th>\n",
              "      <th>agePct12t29</th>\n",
              "      <th>agePct16t24</th>\n",
              "      <th>agePct65up</th>\n",
              "      <th>numbUrban</th>\n",
              "      <th>pctUrban</th>\n",
              "      <th>medIncome</th>\n",
              "      <th>pctWWage</th>\n",
              "      <th>pctWFarmSelf</th>\n",
              "      <th>pctWInvInc</th>\n",
              "      <th>pctWSocSec</th>\n",
              "      <th>pctWPubAsst</th>\n",
              "      <th>pctWRetire</th>\n",
              "      <th>medFamInc</th>\n",
              "      <th>perCapInc</th>\n",
              "      <th>whitePerCap</th>\n",
              "      <th>blackPerCap</th>\n",
              "      <th>indianPerCap</th>\n",
              "      <th>AsianPerCap</th>\n",
              "      <th>OtherPerCap</th>\n",
              "      <th>HispPerCap</th>\n",
              "      <th>NumUnderPov</th>\n",
              "      <th>PctPopUnderPov</th>\n",
              "      <th>PctLess9thGrade</th>\n",
              "      <th>PctNotHSGrad</th>\n",
              "      <th>PctBSorMore</th>\n",
              "      <th>PctUnemployed</th>\n",
              "      <th>PctEmploy</th>\n",
              "      <th>PctEmplManu</th>\n",
              "      <th>PctEmplProfServ</th>\n",
              "      <th>PctOccupManu</th>\n",
              "      <th>PctOccupMgmtProf</th>\n",
              "      <th>MalePctDivorce</th>\n",
              "      <th>MalePctNevMarr</th>\n",
              "      <th>...</th>\n",
              "      <th>PctNotSpeakEnglWell</th>\n",
              "      <th>PctLargHouseFam</th>\n",
              "      <th>PctLargHouseOccup</th>\n",
              "      <th>PersPerOccupHous</th>\n",
              "      <th>PersPerOwnOccHous</th>\n",
              "      <th>PersPerRentOccHous</th>\n",
              "      <th>PctPersOwnOccup</th>\n",
              "      <th>PctPersDenseHous</th>\n",
              "      <th>PctHousLess3BR</th>\n",
              "      <th>MedNumBR</th>\n",
              "      <th>HousVacant</th>\n",
              "      <th>PctHousOccup</th>\n",
              "      <th>PctHousOwnOcc</th>\n",
              "      <th>PctVacantBoarded</th>\n",
              "      <th>PctVacMore6Mos</th>\n",
              "      <th>MedYrHousBuilt</th>\n",
              "      <th>PctHousNoPhone</th>\n",
              "      <th>PctWOFullPlumb</th>\n",
              "      <th>OwnOccLowQuart</th>\n",
              "      <th>OwnOccMedVal</th>\n",
              "      <th>OwnOccHiQuart</th>\n",
              "      <th>RentLowQ</th>\n",
              "      <th>RentMedian</th>\n",
              "      <th>RentHighQ</th>\n",
              "      <th>MedRent</th>\n",
              "      <th>MedRentPctHousInc</th>\n",
              "      <th>MedOwnCostPctInc</th>\n",
              "      <th>MedOwnCostPctIncNoMtg</th>\n",
              "      <th>NumInShelters</th>\n",
              "      <th>NumStreet</th>\n",
              "      <th>PctForeignBorn</th>\n",
              "      <th>PctBornSameState</th>\n",
              "      <th>PctSameHouse85</th>\n",
              "      <th>PctSameCity85</th>\n",
              "      <th>PctSameState85</th>\n",
              "      <th>LandArea</th>\n",
              "      <th>PopDens</th>\n",
              "      <th>PctUsePubTrans</th>\n",
              "      <th>LemasPctOfficDrugUn</th>\n",
              "      <th>ViolentCrimesPerPop</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.19</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.40</td>\n",
              "      <td>...</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.02</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.36</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.84</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.41</td>\n",
              "      <td>...</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.86</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.29</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.04</td>\n",
              "      <td>0.77</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.06</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.45</td>\n",
              "      <td>...</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.85</td>\n",
              "      <td>0.77</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.97</td>\n",
              "      <td>0.96</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.24</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.48</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.65</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.42</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.27</td>\n",
              "      <td>...</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.59</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.38</td>\n",
              "      <td>0.22</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 101 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   population  householdsize  ...  LemasPctOfficDrugUn  ViolentCrimesPerPop\n",
              "0        0.19           0.33  ...                 0.32                 0.20\n",
              "1        0.00           0.16  ...                 0.00                 0.67\n",
              "2        0.00           0.42  ...                 0.00                 0.43\n",
              "3        0.04           0.77  ...                 0.00                 0.12\n",
              "4        0.01           0.55  ...                 0.00                 0.03\n",
              "\n",
              "[5 rows x 101 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CQ523crKHZx"
      },
      "source": [
        "#4. Regression Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty2JFQfnKLM9"
      },
      "source": [
        "We can now move to the task of predicting the value of Violent Crimes per Population from the communities dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLHa2MUOL5rX"
      },
      "source": [
        "We will first randomly split the dataset for the training and testing process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOAT0qUhT3-k"
      },
      "source": [
        "dataset = data.copy()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzjCC1qxKKoM",
        "outputId": "6c8866b7-8c8a-4f96-9f26-e3c9700283c6"
      },
      "source": [
        "X = data.iloc[:, 0:100].values\n",
        "y = data.iloc[:, 100].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1994, 100)\n",
            "(1994,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAgQWCEENB0y"
      },
      "source": [
        "Let's define the first model.\n",
        "\n",
        "Let's have the 1st model with the following configuration:\n",
        "\n",
        "*   1 Hidden Layer with 10 nodes\n",
        "*   ReLu activation function\n",
        "*   Adam Optimizer\n",
        "*   1 batch size\n",
        "*   10 epochs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjfqpZv_WzoY",
        "outputId": "04c59b8d-82dd-4e15-941d-b5f0d70b263a"
      },
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Dense(10, input_dim=100, activation='relu'))\n",
        "model_1.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_1.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_1.fit(X_train, y_train, batch_size = 1, epochs = 10, verbose=0)\n",
        "\n",
        "pred_train_1 = model_1.predict(X_train)\n",
        "pred_test_1 = model_1.predict(X_test)\n",
        "\n",
        "print(\"Model 1 MSE: \", mean_squared_error(y_test, pred_test_1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 1 MSE:  0.019446853467321633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVJrkxR9ADp3"
      },
      "source": [
        "Considering the ViolentCrimesPerPop values are at the range of 0 to 1, the MSE of 0.019 is quite okay.\n",
        "\n",
        "Let's try increasing the number of nodes in the Hidden Layer to 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0D1S8hNaWD1",
        "outputId": "353e3bd2-3a90-436f-adb1-08da2c5de051"
      },
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Dense(50, input_dim=100, activation='relu'))\n",
        "model_2.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_2.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_2.fit(X_train, y_train, batch_size = 1, epochs = 10, verbose=0)\n",
        "\n",
        "pred_train_2 = model_2.predict(X_train)\n",
        "predicted_y_2 = model_2.predict(X_test)\n",
        "\n",
        "print(\"Model 2 MSE: \", mean_squared_error(y_test, predicted_y_2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 2 MSE:  0.018278420430347494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLVWT1pfF7OV"
      },
      "source": [
        "With the nodes in the Hidden Layer increased to 50, we reduced the MSE to 0.018.\n",
        "\n",
        "Let's try adding 25 more nodes to the Hidden Layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGAGljvcbBXA",
        "outputId": "624b249e-9f19-4e84-dad3-1d54cab2bdf7"
      },
      "source": [
        "model_3 = Sequential()\n",
        "model_3.add(Dense(75, input_dim=100, activation='relu'))\n",
        "model_3.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_3.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_3.fit(X_train, y_train, batch_size = 1, epochs = 10, verbose=0)\n",
        "\n",
        "pred_train_3 = model_3.predict(X_train)\n",
        "predicted_y_3 = model_3.predict(X_test)\n",
        "\n",
        "print(\"Model 3 MSE: \", mean_squared_error(y_test, predicted_y_3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 3 MSE:  0.020469206060345815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiTgCOM4Hji1"
      },
      "source": [
        "With 75 nodes in the Hidden Layer our MSE has actually increased to 0.02. \n",
        "\n",
        "Seems like 50 nodes is the best value in the first Hidden Layer so far.\n",
        "\n",
        "Now let's try adding more Hidden Layers in our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_130ELQscbMf",
        "outputId": "521a211a-36ed-4f78-ea3e-5e32c3979e7a"
      },
      "source": [
        "model_4 = Sequential()\n",
        "model_4.add(Dense(50, input_dim=100, activation='relu'))\n",
        "model_4.add(Dense(50, activation='relu'))\n",
        "model_4.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_4.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_4.fit(X_train, y_train, batch_size = 1, epochs = 10, verbose=0)\n",
        "\n",
        "pred_train_4 = model_4.predict(X_train)\n",
        "predicted_y_4 = model_4.predict(X_test)\n",
        "\n",
        "print(\"Model 4 MSE: \", mean_squared_error(y_test, predicted_y_4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 4 MSE:  0.018794383570859864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9tFyPwTWIsgb"
      },
      "source": [
        "With 2 Hidden Layers, each with 50 nodes, our MSE has reduced to 0.18. Let's try reducing the nodes in the 2nd Hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIY-lbcxJtHa",
        "outputId": "945f26fa-341f-4f99-a8b4-f22f847aa621"
      },
      "source": [
        "model_5 = Sequential()\n",
        "model_5.add(Dense(50, input_dim=100, activation='relu'))\n",
        "model_5.add(Dense(25, activation='relu'))\n",
        "model_5.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_5.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_5.fit(X_train, y_train, batch_size = 1, epochs = 10, verbose=0)\n",
        "\n",
        "pred_train_5 = model_5.predict(X_train)\n",
        "predicted_y_5 = model_5.predict(X_test)\n",
        "\n",
        "print(\"Model 5 MSE: \", mean_squared_error(y_test, predicted_y_5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 5 MSE:  0.01827463807331326\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUQyXrQ_Kdz5"
      },
      "source": [
        "With 50 nodes in the 1st HL and 25 in the 2nd HL, we have gained an MSE of 0.182, the best so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSUPLszfSRdT"
      },
      "source": [
        "# Batch Size Value Experimentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8OgnpdEKk0R"
      },
      "source": [
        "Now let's try experimenting with the batch_size and epochs.\n",
        "\n",
        "Let's try increasing the batch size to 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP5ydLWUKjZ3",
        "outputId": "72e437b5-e43b-405e-93cf-2a5a902923e7"
      },
      "source": [
        "model_6 = Sequential()\n",
        "model_6.add(Dense(50, input_dim=100, activation='relu'))\n",
        "model_6.add(Dense(25, activation='relu'))\n",
        "model_6.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_6.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_6.fit(X_train, y_train, batch_size = 50, epochs = 10, verbose=0)\n",
        "\n",
        "pred_train_6 = model_6.predict(X_train)\n",
        "predicted_y_6 = model_6.predict(X_test)\n",
        "\n",
        "print(\"Model 6 MSE: \", mean_squared_error(y_test, predicted_y_6))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 6 MSE:  0.01922983920763258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q939PGRmLja3"
      },
      "source": [
        "The model has yielded 0.024 MSE. Perhaps the model was learning too quickly.\n",
        "\n",
        "Let's try reducing the batch size to 50."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDHtSpSELtDK",
        "outputId": "ac4ddd23-ca1d-48dc-d382-5dea190d3055"
      },
      "source": [
        "model_7 = Sequential()\n",
        "model_7.add(Dense(50, input_dim=100, activation='relu'))\n",
        "model_7.add(Dense(25, activation='relu'))\n",
        "model_7.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_7.fit(X_train, y_train, batch_size = 75, epochs = 10, verbose=0)\n",
        "\n",
        "pred_train_7 = model_7.predict(X_train)\n",
        "predicted_y_7 = model_7.predict(X_test)\n",
        "\n",
        "print(\"Model 7 MSE: \", mean_squared_error(y_test, predicted_y_7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 7 MSE:  0.018611213439503352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tV1AxsuMKkf",
        "outputId": "5d692efb-5fd5-4dc3-882b-846930161421"
      },
      "source": [
        "model_8 = Sequential()\n",
        "model_8.add(Dense(50, input_dim=100, activation='relu'))\n",
        "model_8.add(Dense(25, activation='relu'))\n",
        "model_8.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_8.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_8.fit(X_train, y_train, batch_size = 100, epochs = 10, verbose=0)\n",
        "\n",
        "pred_train_8 = model_8.predict(X_train)\n",
        "predicted_y_8 = model_8.predict(X_test)\n",
        "\n",
        "print(\"Model 8 MSE: \", mean_squared_error(y_test, predicted_y_8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 8 MSE:  0.019692743721413004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7UcLnvJMDJ0"
      },
      "source": [
        "And agai, the model has performed worse. It seems that a high batch size is not viable for this case.\n",
        "\n",
        "Let's try tuning it down to 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r56mJmsxNZqY",
        "outputId": "cf3fa2cc-ad05-4dea-e8ac-57f371475d61"
      },
      "source": [
        "model_8 = Sequential()\n",
        "model_8.add(Dense(50, input_dim=100, activation='relu'))\n",
        "model_8.add(Dense(25, activation='relu'))\n",
        "model_8.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_8.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_8.fit(X_train, y_train, batch_size = 5, epochs = 10, verbose=0)\n",
        "\n",
        "pred_train_8 = model_8.predict(X_train)\n",
        "predicted_y_8 = model_8.predict(X_test)\n",
        "\n",
        "print(\"Model 8 MSE: \", mean_squared_error(y_test, predicted_y_8))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 8 MSE:  0.018686361001895736\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isc_gEQVNwyd"
      },
      "source": [
        "The model has yielded a quite performance of 0.0186 MSE.\n",
        "\n",
        "Let's try reducing it again to 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0pYSU4nN3ck",
        "outputId": "6474c564-5449-49be-d20a-10c7bdfdf2e3"
      },
      "source": [
        "model_9 = Sequential()\n",
        "model_9.add(Dense(50, input_dim=100, activation='relu'))\n",
        "model_9.add(Dense(25, activation='relu'))\n",
        "model_9.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_9.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_9.fit(X_train, y_train, batch_size = 3, epochs = 10, verbose=0)\n",
        "\n",
        "pred_train_9 = model_9.predict(X_train)\n",
        "predicted_y_9 = model_9.predict(X_test)\n",
        "\n",
        "print(\"Model 9 MSE: \", mean_squared_error(y_test, predicted_y_9))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 9 MSE:  0.018593758353298746\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK_KpS7POZag"
      },
      "source": [
        "The model has yielded the one the best performance so far at 0.01859 MSE.\n",
        "\n",
        "It seems that the optimal range of batch size is 1 - 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_oknEWvSVFv"
      },
      "source": [
        "# Epoch Value Experimentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4fXSE5yOsC8"
      },
      "source": [
        "Now let's try experimenting with the value of epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhtiRCckOYoR",
        "outputId": "1c5d9396-e534-45aa-ce5d-cef536c588ac"
      },
      "source": [
        "model_10 = Sequential()\n",
        "model_10.add(Dense(50, input_dim=100, activation='relu'))\n",
        "model_10.add(Dense(25, activation='relu'))\n",
        "model_10.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_10.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_10.fit(X_train, y_train, batch_size = 3, epochs = 50, verbose=0)\n",
        "\n",
        "pred_train_10 = model_10.predict(X_train)\n",
        "predicted_y_10 = model_10.predict(X_test)\n",
        "\n",
        "print(\"Model 10 MSE: \", mean_squared_error(y_test, predicted_y_10))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 10 MSE:  0.020698697809559963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUooQT31PH1j",
        "outputId": "8c50cc34-f85b-4db1-af42-5f7a8bb37363"
      },
      "source": [
        "model_11 = Sequential()\n",
        "model_11.add(Dense(50, input_dim=100, activation='relu'))\n",
        "model_11.add(Dense(25, activation='relu'))\n",
        "model_11.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_11.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_11.fit(X_train, y_train, batch_size = 3, epochs = 100, verbose=0)\n",
        "\n",
        "pred_train_11 = model_11.predict(X_train)\n",
        "predicted_y_11 = model_11.predict(X_test)\n",
        "\n",
        "print(\"Model 11 MSE: \", mean_squared_error(y_test, predicted_y_11))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 11 MSE:  0.024563161454921264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2sQuVdyQbBF"
      },
      "source": [
        "It seems that a high epoch number is not viable for our case, as it has yielded a high MSE of 0.245, when compared to our previous results.\n",
        "\n",
        "Let's keep it at 10."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDZ2HYOGSdrn"
      },
      "source": [
        "# Hidden Layer Experimentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4ymMGgXQmLd"
      },
      "source": [
        "Let's try experimenting with more Hidden Layers now.\n",
        "Let's try adding 1 more Hidden Layer with 10 nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRmCwjPZQlfh",
        "outputId": "23e0735d-2269-400f-df3d-df5182a0bd3d"
      },
      "source": [
        "model_12 = Sequential()\n",
        "model_12.add(Dense(50, input_dim=100, activation='relu'))\n",
        "model_12.add(Dense(25, activation='relu'))\n",
        "model_12.add(Dense(10, activation='relu'))\n",
        "model_12.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_12.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_12.fit(X_train, y_train, batch_size = 3, epochs = 10, verbose=0)\n",
        "\n",
        "pred_train_12 = model_12.predict(X_train)\n",
        "predicted_y_12 = model_12.predict(X_test)\n",
        "\n",
        "print(\"Model 12 MSE: \", mean_squared_error(y_test, predicted_y_12))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 12 MSE:  0.01815367035511721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pew3JjgsQ9ah"
      },
      "source": [
        "With the addition of another Hidden Layer with 10 nodes, we have gained the best performance so far with 0.1815 MSE.\n",
        "\n",
        "Let's try reducing the node of the 3rd Hidden Layer to 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj94j-rbQ9AA",
        "outputId": "a28f98c6-06a2-420a-bb32-97f216293fe0"
      },
      "source": [
        "model_13 = Sequential()\n",
        "model_13.add(Dense(50, input_dim=100, activation='relu'))\n",
        "model_13.add(Dense(25, activation='relu'))\n",
        "model_13.add(Dense(5, activation='relu'))\n",
        "model_13.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_13.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_13.fit(X_train, y_train, batch_size = 3, epochs = 10, verbose=0)\n",
        "\n",
        "pred_train_13 = model_13.predict(X_train)\n",
        "predicted_y_13 = model_13.predict(X_test)\n",
        "\n",
        "print(\"Model 12 MSE: \", mean_squared_error(y_test, predicted_y_13))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 12 MSE:  0.018655000940964145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftJy5xqKRRhb"
      },
      "source": [
        "We have gained a good performance, but it seems 10 nodes in the 3rd Hidden Layer was better. Let's keep the value at that for now.\n",
        "\n",
        "Let's try adding another Hidden Layer, a total of 3 now.\n",
        "Let's add 5 nodes to that new Hidden Layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewhBuz3cRQhr",
        "outputId": "8fec8180-0f8e-4614-b067-ac6de2e947f6"
      },
      "source": [
        "model_14 = Sequential()\n",
        "model_14.add(Dense(50, input_dim=100, activation='relu'))\n",
        "model_14.add(Dense(25, activation='relu'))\n",
        "model_14.add(Dense(10, activation='relu'))\n",
        "model_14.add(Dense(5, activation='relu'))\n",
        "model_14.add(Dense(1, kernel_initializer='normal'))\n",
        "\n",
        "# Compile model\n",
        "model_14.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "# evaluate model\n",
        "model_14.fit(X_train, y_train, batch_size = 3, epochs = 10, verbose=0)\n",
        "\n",
        "pred_train_14 = model_14.predict(X_train)\n",
        "predicted_y_14 = model_14.predict(X_test)\n",
        "\n",
        "print(\"Model 14 MSE: \", mean_squared_error(y_test, predicted_y_14))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model 14 MSE:  0.05214890060385184\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HY_FEWyR79F"
      },
      "source": [
        "With the addition of the 4th Hidden Layer, we have gained the worst performance so far. \n",
        "\n",
        "According to our results above, 2 Hidden Layers seem to be the best value so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccrUzxeW-vjN"
      },
      "source": [
        "# Regression Task Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iegsgD5T-x22"
      },
      "source": [
        "With the results of our experimentations of the Regression Task, we can form some conclusions about the parameters and its values to gain the best performing model.\n",
        "\n",
        "1.   **Number of Hidden Layers and number of its nodes** \n",
        "* Based on our experiments, the model with best peformance had 3 Hidden Layers: 1st layer with 50 nodes, 2nd layer with 25, and 3rd layer with 10 nodes.\n",
        "\n",
        "2.   **Number of Epochs**\n",
        "* Based on our experiments, the model with best peformance had 10 epochs. In general, based on our experiments, the higher the epoch, the worse the performance. This is perhaps due to the model overfitting the data.\n",
        "\n",
        "3. **Number of Batch Size**\n",
        "* Based on our experiments, the model with best peformance had a batch size of 3. In general, based on our experiments, the higher the batch size, the worse the performance, similar to epoch. Again, this is perhaps due to the model overfitting the data.\n",
        "\n",
        "Based on our experiments, the best value range for each parameters are:\n",
        "\n",
        "* **Number of Hidden Layers**: 2 - 3\n",
        "* **Nodes in a Hidden Layer**: 10 - 50\n",
        "* **Number of Epochs**: 10 - 20\n",
        "* **Number of Batch Size**: 1 - 10\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrAQsOH4dv_3"
      },
      "source": [
        "#5. Classification Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV6v4mRCpGof"
      },
      "source": [
        "For the Classification Task, let's begin by making a duplicate of the preprocessed data to a new Pandas Dataframe called 'dataset' as follows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2S5SFYlfWTD"
      },
      "source": [
        "dataset = data.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIgUN6GFpSd0"
      },
      "source": [
        "Now let's make the classification class by creating a new class based on the values of the 'ViolentCrimesPerPop' attribute.\n",
        "\n",
        "We'll assign the class of the attribute to 'Low' if the \n",
        "value is lower or equals to 0.3; 'Medium' if it is between 0.31 to 0.6; and 'High' if it is above 0.61.\n",
        "\n",
        "\n",
        "*  'Low' = value < 0.3 \n",
        "*  'Medium' = 0.31 <= value <= 0.6 \n",
        "* 'High' = >= 0.61\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29FHyaJIi6xR",
        "outputId": "9834adb5-8238-401e-a8b9-d88657f2df93"
      },
      "source": [
        "for i in range (0, len(dataset.ViolentCrimesPerPop)):\n",
        "  if dataset['ViolentCrimesPerPop'][i] <= 0.3:\n",
        "    dataset.ViolentCrimesPerPop[i] = 'Low'\n",
        "  elif dataset['ViolentCrimesPerPop'][i] > 0.3 and dataset['ViolentCrimesPerPop'][i] <= 0.6:\n",
        "    dataset.ViolentCrimesPerPop[i] = 'Medium'\n",
        "  elif dataset['ViolentCrimesPerPop'][i] > 0.6:\n",
        "    dataset.ViolentCrimesPerPop[i] = 'High'"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb7QPjshrcVG"
      },
      "source": [
        "Now let's One Hot Encode the classes of 'Low', 'Medium', and 'High'. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YTL1ll5fksZ"
      },
      "source": [
        "enc_data = pd.get_dummies(dataset[['ViolentCrimesPerPop']])\n",
        "res = pd.concat([dataset, enc_data], axis=1)\n",
        "res = res.drop(['ViolentCrimesPerPop'], axis=1)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phfCwI0XUq9u",
        "outputId": "43e27826-486b-4f03-83fb-54c25d9a1651"
      },
      "source": [
        "X_c = res.iloc[:, 0:100].values\n",
        "y_c = res.iloc[:, 100:103].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_c, y_c, test_size = 0.3, random_state = 1)\n",
        "\n",
        "print(X_c.shape)\n",
        "print(y_c.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1994, 100)\n",
            "(1994, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoIAPNEz2k8-"
      },
      "source": [
        "# Hidden Layer Experimentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySXBPqbdsBc9"
      },
      "source": [
        "Let's begin by creating a Baseline Model by adding 1 Hidden Layer with 50 nodes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czlLFe7dwTTa",
        "outputId": "482a036e-4507-490c-ba9b-fc641764bd92"
      },
      "source": [
        "# define the keras model\n",
        "cmodel_1 = Sequential()\n",
        "cmodel_1.add(Dense(50, input_dim=100, activation='relu'))\n",
        "cmodel_1.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "cmodel_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "cmodel_1.fit(X_c, y_c, epochs=50, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy_1 = cmodel_1.evaluate(X_c, y_c)\n",
        "print('Training Accuracy: %.2f' % (accuracy_1*100), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4230 - accuracy: 0.8250\n",
            "Training Accuracy: 82.50 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLCKx4c1wryR"
      },
      "source": [
        "With only 1 Hidden Layer with 50 nodes, we have gained an accuracy of 82.50%. Pretty good.\n",
        "\n",
        "Let's try increasing the nodes to 75."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xs-inePJ3fp7",
        "outputId": "73872c21-c1d6-4d62-d7a4-7aa37e767fe7"
      },
      "source": [
        "# define the keras model\n",
        "cmodel_2 = Sequential()\n",
        "cmodel_2.add(Dense(75, input_dim=100, activation='relu'))\n",
        "cmodel_2.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "cmodel_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "cmodel_2.fit(X_c, y_c, epochs=50, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy_2 = cmodel_2.evaluate(X_c, y_c)\n",
        "print('Training Accuracy: %.2f' % (accuracy_2*100), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3318 - accuracy: 0.8701\n",
            "Training Accuracy: 87.01 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWdT3-zT23zB"
      },
      "source": [
        "It seems that our accuracy has increased to 87.01%. \n",
        "\n",
        "Let's try increasing the nodes to 100."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuEVUJ383AdW",
        "outputId": "423e3ff7-3bf3-4051-b16f-ba1bf02b7f45"
      },
      "source": [
        "# define the keras model\n",
        "cmodel_3 = Sequential()\n",
        "cmodel_3.add(Dense(100, input_dim=100, activation='relu'))\n",
        "cmodel_3.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "cmodel_3.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "cmodel_3.fit(X_c, y_c, epochs=50, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy_3 = cmodel_3.evaluate(X_c, y_c)\n",
        "print('Training Accuracy: %.2f' % (accuracy_3*100), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3231 - accuracy: 0.8731\n",
            "Training Accuracy: 87.31 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjZ-LhrZ3bj8"
      },
      "source": [
        "Having 100 nodes in the 1st Hidden Layer has yielded the best accuracy so far, reaching 87.31%.\n",
        "\n",
        "It seems that around 50-100 is the sweet spot for the nodes in the 1st Hidden Layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONRTZw7iwZmV"
      },
      "source": [
        "Let's try adding another Hidden Layer with 100 nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9ZuWs104UIi",
        "outputId": "96cf04e5-6280-4909-fc2a-32039253227c"
      },
      "source": [
        "# define the keras model\n",
        "cmodel_4 = Sequential()\n",
        "cmodel_4.add(Dense(100, input_dim=100, activation='relu'))\n",
        "cmodel_4.add(Dense(100, activation='relu'))\n",
        "cmodel_4.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "cmodel_4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "cmodel_4.fit(X_c, y_c, epochs=50, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy_4 = cmodel_4.evaluate(X_c, y_c)\n",
        "print('Training Accuracy: %.2f' % (accuracy_4*100), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.1993 - accuracy: 0.9238\n",
            "Training Accuracy: 92.38 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpUeF8e24iLX"
      },
      "source": [
        "The model with a second Hidden Layer with 100 nodes has achieved the highest accuracy so far, at 92.38% \n",
        "\n",
        "Let's try 75 nodes in the 2nd Hidden Layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74rH8F-w4yJa",
        "outputId": "598cff22-a3aa-4e73-9189-4c618a5fd017"
      },
      "source": [
        "# define the keras model\n",
        "cmodel_5 = Sequential()\n",
        "cmodel_5.add(Dense(100, input_dim=100, activation='relu'))\n",
        "cmodel_5.add(Dense(75, activation='relu'))\n",
        "cmodel_5.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "cmodel_5.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "cmodel_5.fit(X_c, y_c, epochs=50, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy_5 = cmodel_5.evaluate(X_c, y_c)\n",
        "print('Training Accuracy: %.2f' % (accuracy_5*100), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.2087 - accuracy: 0.9313\n",
            "Training Accuracy: 93.13 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyynbCyx5EEk"
      },
      "source": [
        "With 75 nodes in the 2nd Hidden Layer, our model has improved, with the best accuracy so far at 93.13%. \n",
        "\n",
        "How about 50 nodes in the 2nd Hidden Layer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZImRzsf5C0F",
        "outputId": "6f9f571b-ea39-4d75-8e74-86935d6b0c73"
      },
      "source": [
        "# define the keras model\n",
        "cmodel_6 = Sequential()\n",
        "cmodel_6.add(Dense(100, input_dim=100, activation='relu'))\n",
        "cmodel_6.add(Dense(50, activation='relu'))\n",
        "cmodel_6.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "cmodel_6.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "cmodel_6.fit(X_c, y_c, epochs=50, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy_6 = cmodel_6.evaluate(X_c, y_c)\n",
        "print('Training Accuracy: %.2f' % (accuracy_6*100), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.2535 - accuracy: 0.8987\n",
            "Training Accuracy: 89.87 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYTh51pY5anZ"
      },
      "source": [
        "With 50 nodes in the 2nd Hidden Layer, our accuracy has decreased. As such, let's keep 75 nodes for the 2nd HL.\n",
        "\n",
        "How about a 3rd HL? Let's try adding another Hidden Layer with 50 nodes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30WDz-315mGM",
        "outputId": "aab92e25-0466-4824-a482-737ddc335376"
      },
      "source": [
        "# define the keras model\n",
        "cmodel_7 = Sequential()\n",
        "cmodel_7.add(Dense(100, input_dim=100, activation='relu'))\n",
        "cmodel_7.add(Dense(75, activation='relu'))\n",
        "cmodel_7.add(Dense(50, activation='relu'))\n",
        "cmodel_7.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "cmodel_7.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "cmodel_7.fit(X_c, y_c, epochs=50, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy_7 = cmodel_7.evaluate(X_c, y_c)\n",
        "print('Training Accuracy: %.2f' % (accuracy_7*100), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.1816 - accuracy: 0.9293\n",
            "Training Accuracy: 92.93 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmXonZHS6GpV"
      },
      "source": [
        "It seems that our model was not able to improve, but still generated a good result.\n",
        "\n",
        "How about aat 75 Hidden Layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epr3qnoK5zBf",
        "outputId": "c861f13f-fc61-48bf-8c5e-de63173337a3"
      },
      "source": [
        "# define the keras model\n",
        "cmodel_8 = Sequential()\n",
        "cmodel_8.add(Dense(100, input_dim=100, activation='relu'))\n",
        "cmodel_8.add(Dense(75, activation='relu'))\n",
        "cmodel_8.add(Dense(75, activation='relu'))\n",
        "cmodel_8.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "cmodel_8.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "cmodel_8.fit(X_c, y_c, epochs=50, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy_8 = cmodel_8.evaluate(X_c, y_c)\n",
        "print('Training Accuracy: %.2f' % (accuracy_8*100), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.9338\n",
            "Training Accuracy: 93.38 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r751YA326gct"
      },
      "source": [
        "With 75 nodes in the 3rd Hidden Layer, our model has improved, with the best accuracy so far at 93.38%, although it wasn't a huge increase."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKyis6V-8ZdD"
      },
      "source": [
        "# Epoch Value Experimentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8wVMueI7JBq"
      },
      "source": [
        "Now let's try experimenting with the value of Epochs.\n",
        "\n",
        "Let's try reducing to 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt8Dlr9r6t8P",
        "outputId": "dfc2190b-7bd7-47a7-fad6-a90c1e9c4a81"
      },
      "source": [
        "# define the keras model\n",
        "cmodel_9 = Sequential()\n",
        "cmodel_9.add(Dense(100, activation='relu'))\n",
        "cmodel_9.add(Dense(75, activation='relu'))\n",
        "cmodel_9.add(Dense(75, activation='relu'))\n",
        "cmodel_9.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "cmodel_9.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "cmodel_9.fit(X_c, y_c, epochs=10, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy_9 = cmodel_9.evaluate(X_c, y_c)\n",
        "print('Training Accuracy: %.2f' % (accuracy_9*100), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.3980 - accuracy: 0.8330\n",
            "Training Accuracy: 83.30 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtFzIrSr7S9j"
      },
      "source": [
        "It seems that our model has decreased in performance. It seems that lowering the Epoch would decrease the performance. Let's test that theory by lowering the Epoch to 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7w_QTVY7Xrv",
        "outputId": "030cf409-06fa-4d55-d8c5-1017f63d59b6"
      },
      "source": [
        "# define the keras model\n",
        "cmodel_10 = Sequential()\n",
        "cmodel_10.add(Dense(100, input_dim=100, activation='relu'))\n",
        "cmodel_10.add(Dense(75, activation='relu'))\n",
        "cmodel_10.add(Dense(75, activation='relu'))\n",
        "cmodel_10.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "cmodel_10.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "cmodel_10.fit(X_c, y_c, epochs=5, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy_10 = cmodel_10.evaluate(X_c, y_c)\n",
        "print('Training Accuracy: %.2f' % (accuracy_10*100), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.4201 - accuracy: 0.8270\n",
            "Training Accuracy: 82.70 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu83WkIL7m2E"
      },
      "source": [
        "It seems our suspicion was right, as our model's accuracy has decreased with a lower Epoch.\n",
        "\n",
        "Now let's try increasing it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRM6G3lV7x8J",
        "outputId": "841d2ef1-bac5-452f-8f1f-2bf3a1b30fa7"
      },
      "source": [
        "# define the keras model\n",
        "cmodel_11 = Sequential()\n",
        "cmodel_11.add(Dense(100, input_dim=100, activation='relu'))\n",
        "cmodel_11.add(Dense(75, activation='relu'))\n",
        "cmodel_11.add(Dense(75, activation='relu'))\n",
        "cmodel_11.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "cmodel_11.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "cmodel_11.fit(X_c, y_c, epochs=100, batch_size=10, verbose=0)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy_11 = cmodel_11.evaluate(X_c, y_c)\n",
        "print('Training Accuracy: %.2f' % (accuracy_11*100), '%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.1480 - accuracy: 0.9524\n",
            "Training Accuracy: 95.24 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDD37aAA8LRX"
      },
      "source": [
        "At 100 epochs, our model has reached the best accuracy so far, at 95.24%. As such, let's keep the value at 100."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gUCZMOCBDVn"
      },
      "source": [
        "# Batch Size Experimentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2U96wPGw-XnV"
      },
      "source": [
        "Now let's try experimenting the value of the batch size with our best model so far.\n",
        "\n",
        "Let's begin by halving the value to 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdjdbFQR-cmD",
        "outputId": "105c1c81-2e8f-40b0-b4fa-da7a03016c43"
      },
      "source": [
        "# define the keras model\n",
        "cmodel_12 = Sequential()\n",
        "cmodel_12.add(Dense(100, input_dim=100, activation='relu'))\n",
        "cmodel_12.add(Dense(75, activation='relu'))\n",
        "cmodel_12.add(Dense(75, activation='relu'))\n",
        "cmodel_12.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "cmodel_12.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "cmodel_12.fit(X_c, y_c, epochs=100, batch_size=5, verbose=0)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy_12 = cmodel_12.evaluate(X_c, y_c)\n",
        "print('Training Accuracy: %.2f' % (accuracy_12*100), '%')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 1s 1ms/step - loss: 0.0584 - accuracy: 0.9804\n",
            "Training Accuracy: 98.04 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN2hMNWDAHRM"
      },
      "source": [
        "At a batch size of 5, the model has achieved the best accuracy so far at 98.04%.\n",
        "\n",
        "Let's try reducing it to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hiuF_Ji-_K0",
        "outputId": "33ba7436-68d4-4478-c4e9-7cd87a81e96c"
      },
      "source": [
        "# define the keras model\n",
        "cmodel_13 = Sequential()\n",
        "cmodel_13.add(Dense(100, input_dim=100, activation='relu'))\n",
        "cmodel_13.add(Dense(75, activation='relu'))\n",
        "cmodel_13.add(Dense(75, activation='relu'))\n",
        "cmodel_13.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "cmodel_13.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "cmodel_13.fit(X_c, y_c, epochs=100, batch_size=1, verbose=0)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy_13 = cmodel_13.evaluate(X_c, y_c)\n",
        "print('Training Accuracy: %.2f' % (accuracy_13*100), '%')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.1605 - accuracy: 0.9363\n",
            "Training Accuracy: 93.63 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc_dpr9VAQpE"
      },
      "source": [
        "It seems that the model has performed very well, at 93.63%. However, it did not beat the best performance, which was gained with a batch size of 5.\n",
        "\n",
        "Let's try increasing the batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F80WMcvKAqyG",
        "outputId": "304d10a6-2ff0-41ad-aea8-536db156e45c"
      },
      "source": [
        "# define the keras model\n",
        "cmodel_14 = Sequential()\n",
        "cmodel_14.add(Dense(100, input_dim=100, activation='relu'))\n",
        "cmodel_14.add(Dense(75, activation='relu'))\n",
        "cmodel_14.add(Dense(75, activation='relu'))\n",
        "cmodel_14.add(Dense(3, activation='sigmoid'))\n",
        "\n",
        "# compile the keras model\n",
        "cmodel_14.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# fit the keras model on the dataset\n",
        "cmodel_14.fit(X_c, y_c, epochs=100, batch_size=50, verbose=0)\n",
        "\n",
        "# evaluate the keras model\n",
        "_, accuracy_14 = cmodel_14.evaluate(X_c, y_c)\n",
        "print('Training Accuracy: %.2f' % (accuracy_14*100), '%')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 0s 1ms/step - loss: 0.0708 - accuracy: 0.9794\n",
            "Training Accuracy: 97.94 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fvvc9l-kA38n"
      },
      "source": [
        "The accuracy we have gained is good, but not as good as the batch size of 5.\n",
        "\n",
        "It seems that the batch size of 5 is the best performing so far."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlvBfwKgBZ3o"
      },
      "source": [
        "# Classification Task Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNoBVR2nBdad"
      },
      "source": [
        "With the results of our experimentations of the Classification Task, we can form some conclusions about the parameters and its values to gain the best performing model.\n",
        "\n",
        "1.   **Number of Hidden Layers and number of its nodes** \n",
        "* Based on our experiments, the model with best peformance had 3 Hidden Layers: 1st layer with 100 nodes, 2nd layer with 75, and 3rd layer with 75 nodes.\n",
        "\n",
        "2.   **Number of Epochs**\n",
        "* Based on our experiments, the model with best peformance had 100 epochs. In general, based on our experiments, the higher the epoch, the better the performance. This is the opposite case for the Regression Task, where the higher the epoch, the worse the performance.\n",
        "\n",
        "3.   **Value of Batch Size**\n",
        "* Based on our experiments, the model with best peformance had a batch size of 5. In general, based on our experiments, the bigger the batch size, the better the performance. \n",
        "This is the opposite case for the Regression Task, where the bigger the batch size, the worse the performance.\n",
        "\n",
        "Based on our experiments, the best value range for each parameters are:\n",
        "\n",
        "* **Number of Hidden Layers**: 2 - 3\n",
        "* **Nodes in a Hidden Layer**: 75 - 100\n",
        "* **Number of Epochs**: 50 - 100\n",
        "* **Value of Batch Size**: 5 - 50\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRpPLoVbB8_Q"
      },
      "source": [
        "# Regression Task and Classification Task Differences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2-Y17GgCAi3"
      },
      "source": [
        "Based on our experiments for the tasks of Regression and Classification, there are some clear differences in parameter values. \n",
        "\n",
        "With the results of our experimentations of the Regression Task, we can form some conclusions about the parameters and its values to gain the best performing model.\n",
        "\n",
        "1.   **Number of Hidden Layers** \n",
        "* Based on our experiments, the best performing model both in Regression and Classification task utilized the same number of Hidden Layers at 3 Hidden Layers.\n",
        "\n",
        "2. **Number of Nodes in Hidden Layer**\n",
        "* Based on our experiments, a higher number of nodes in the Hidden Layers is better for the Classification task, whereas a lower number of nodes is better for the Regression task. \n",
        "\n",
        "3.   **Number of Epochs and Batch Size**\n",
        "* Based on our experiments, a higher epoch and batch size is better for the Classification task, whereas a lower epoch and batch size is better for the Regression task. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwtIo9tJBjAq"
      },
      "source": [
        "# Final Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cI94wrv2BpY5"
      },
      "source": [
        "For the Regression Task, the best performing model had the following layer configurations:\n",
        "\n",
        "3 Hidden Layers with number of nodes:\n",
        "* 50 -> 25 -> 10\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "qwetaz2WDIEP",
        "outputId": "4cbecccd-a2af-43f3-9445-5b384e402c27"
      },
      "source": [
        "plot_model(model_12, show_shapes=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0om8PGeDQPW"
      },
      "source": [
        "For the Classification Task:\n",
        "3 Hidden Layers with number of nodes:\n",
        "* 100 -> 75 -> 75 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "5-HlqK2iEod8",
        "outputId": "083fe9bb-8d26-4d69-f6e5-f48864f9c373"
      },
      "source": [
        "plot_model(cmodel_12, show_shapes=True)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}